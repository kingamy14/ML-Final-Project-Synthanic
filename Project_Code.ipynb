{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvxFSS0jEKhO"
      },
      "source": [
        "Import training and testing data from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYGslJgtasX-"
      },
      "source": [
        "trainurl = 'https://raw.githubusercontent.com/kingamy14/synthantic/main/train.csv'\n",
        "#testurl = 'https://raw.githubusercontent.com/kingamy14/synthantic/main/test.csv'\n",
        "\n",
        "import pandas as pd\n",
        "traindf = pd.DataFrame(pd.read_csv(trainurl, index_col='PassengerId'))\n",
        "#testdf = pd.DataFrame(pd.read_csv(testurl, index_col='PassengerId'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNjQ5KIBEQj5"
      },
      "source": [
        "Find survival rate for different groups of people"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko3rvZWVBVUy",
        "cellView": "form"
      },
      "source": [
        "#@title print survival rate\n",
        "print('Percentage of survivors: '+str(traindf['Survived'].sum()/len(traindf)))\n",
        "\n",
        "females = traindf.groupby(['Sex']).get_group('female')\n",
        "femalesurvivors = traindf.groupby(['Sex']).get_group('female')['Survived'].sum()\n",
        "pctfemale = femalesurvivors/len(females)\n",
        "print('Percentage of females survivors: '+str(pctfemale))\n",
        "\n",
        "males = traindf.groupby(['Sex']).get_group('male')\n",
        "malesurvivors = traindf.groupby(['Sex']).get_group('male')['Survived'].sum()\n",
        "pctmale = malesurvivors/len(males)\n",
        "print('Percentage of males survivors: '+str(pctmale))\n",
        "\n",
        "Cherbourg = traindf.groupby(['Embarked']).get_group('C')\n",
        "Cherbourgsurvivors = traindf.groupby(['Embarked']).get_group('C')['Survived'].sum()\n",
        "pctCherbourg = Cherbourgsurvivors/len(Cherbourg)\n",
        "print('Percentage of Cherbourg survivors: '+str(pctCherbourg))\n",
        "\n",
        "Queenstown = traindf.groupby(['Embarked']).get_group('Q')\n",
        "Queenstownsurvivors = traindf.groupby(['Embarked']).get_group('Q')['Survived'].sum()\n",
        "pctQueenstown = Queenstownsurvivors/len(Queenstown)\n",
        "print('Percentage of Queenstown survivors: '+str(pctQueenstown))\n",
        "\n",
        "Southampton = traindf.groupby(['Embarked']).get_group('S')\n",
        "Southamptonsurvivors = traindf.groupby(['Embarked']).get_group('S')['Survived'].sum()\n",
        "pctSouthampton = Southamptonsurvivors/len(Southampton)\n",
        "print('Percentage of Southampton survivors: '+str(pctSouthampton))\n",
        "\n",
        "Southampton = traindf.groupby(['Embarked']).get_group('S')\n",
        "Southamptonsurvivors = traindf.groupby(['Embarked']).get_group('S')['Survived'].sum()\n",
        "pctSouthampton = Southamptonsurvivors/len(Southampton)\n",
        "print('Percentage of Southampton survivors: '+str(pctSouthampton))\n",
        "\n",
        "firstclass = traindf.groupby(['Pclass']).get_group(1)\n",
        "firstclasssurvivors = traindf.groupby(['Pclass']).get_group(1)['Survived'].sum()\n",
        "pctfirstclass = firstclasssurvivors/len(firstclass)\n",
        "print('Percentage of Upper class survivors: '+str(pctfirstclass))\n",
        "\n",
        "secondclass = traindf.groupby(['Pclass']).get_group(2)\n",
        "secondclasssurvivors = traindf.groupby(['Pclass']).get_group(2)['Survived'].sum()\n",
        "pctsecondclass = secondclasssurvivors/len(secondclass)\n",
        "print('Percentage of Middle class survivors: '+str(pctsecondclass))\n",
        "\n",
        "thirdclass = traindf.groupby(['Pclass']).get_group(3)\n",
        "thirdclasssurvivors = traindf.groupby(['Pclass']).get_group(3)['Survived'].sum()\n",
        "pctthirdclass = thirdclasssurvivors/len(thirdclass)\n",
        "print('Percentage of Lower class survivors: '+str(pctthirdclass))\n",
        "\n",
        "thirdclass = traindf.groupby(['Pclass']).get_group(3)\n",
        "thirdclasssurvivors = traindf.groupby(['Pclass']).get_group(3)['Survived'].sum()\n",
        "pctthirdclass = thirdclasssurvivors/len(thirdclass)\n",
        "print('Percentage of 3rd class survivors: '+str(pctthirdclass))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fykbc65fEay_"
      },
      "source": [
        "Find basic statistics on the two datasets to look for major differences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exspkoz-ZlYm"
      },
      "source": [
        "traindf.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsISsu1Z_l3W"
      },
      "source": [
        "testdf.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oslyAiReEgdH"
      },
      "source": [
        "Clean data: Turn continuous variables (Age and Fare) into discrete bins and add new data attribute (Family Size)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TeCWof57uWh",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "e9b5775a-c569-419b-b217-6ffc6a580de1"
      },
      "source": [
        "#@title bin age and fare\n",
        "#group Age and Fare into bins as new columns\n",
        "agebins = [0,10,20,30,40,50,60,70,80,90]\n",
        "traindf['AgeBin'] = pd.cut(traindf['Age'], agebins)\n",
        "farebins = [0,20,40,60,80,100,150,300,500,750]\n",
        "traindf['FareBin'] = pd.cut(traindf['Fare'], farebins)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ed8e1b3ba800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#group Age and Fare into bins as new columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0magebins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtraindf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AgeBin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magebins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfarebins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m750\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtraindf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FareBin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fare'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfarebins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_fDwW9YqnBX"
      },
      "source": [
        "#add new columns for family size\n",
        "traindf['FamSize'] = traindf['SibSp'] + traindf['Parch'] + 1\n",
        "testdf['FamSize'] = testdf['SibSp'] + testdf['Parch'] + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I4Jm4AmEs2t"
      },
      "source": [
        "Plot visualizations of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaZbfYWGB7Pe"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "import numpy as np\n",
        "sns.set(rc={'figure.figsize':(14, 5)})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHydf3Llg9mQ",
        "cellView": "form"
      },
      "source": [
        "#@title pclass\n",
        "## PCLASS\n",
        "fig, ax = plt.subplots(1,2)\n",
        "\n",
        "sns.barplot(x = 'Pclass', y = 'Survived', data = traindf, ax=ax[0])\n",
        "ax[0].set_title('Percentage of Survivors in each SES Class')\n",
        "\n",
        "sns.countplot(x = 'Pclass', data = traindf, ax=ax[1])\n",
        "ax[1].set_title('Total Number of People in each SES Class')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBnU9lJGg_YT",
        "cellView": "form"
      },
      "source": [
        "#@title sex\n",
        "## SEX\n",
        "fig, ax = plt.subplots(1,2)\n",
        "\n",
        "sns.barplot(x = 'Sex', y = 'Survived', data = traindf, ax=ax[0])\n",
        "ax[0].set_title('Percentage of Surivors in each Gender')\n",
        "\n",
        "sns.countplot(x = 'Sex', data = traindf, ax=ax[1])\n",
        "ax[1].set_title('Total Number of Males and Females')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rqAAOrvhB5n",
        "cellView": "form"
      },
      "source": [
        "#@title sipsp\n",
        "## SIBSP\n",
        "sns.set(rc={'figure.figsize':(16, 7)})\n",
        "fig, ax = plt.subplots(1,2)\n",
        "\n",
        "sns.barplot(x = 'SibSp', y = 'Survived', data = traindf, ax=ax[0])\n",
        "ax[0].set_title('Percentage of Surivors by Number of Siblings/Spouses On Board')\n",
        "\n",
        "sns.countplot(x = 'SibSp', data = traindf, ax=ax[1])\n",
        "ax[1].set_title('Total Number of Siblings and Spouses On Board')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYogKlh7hCE9",
        "cellView": "form"
      },
      "source": [
        "#@title parch\n",
        "## PARCH\n",
        "fig, ax = plt.subplots(1,2)\n",
        "\n",
        "sns.barplot(x = 'Parch', y = 'Survived', data = traindf, ax=ax[0])\n",
        "ax[0].set_title('Percentage of Surivors by Number of Parents/Children On Board')\n",
        "\n",
        "sns.countplot(x = 'Parch', data = traindf, ax=ax[1])\n",
        "ax[1].set_title('Total Number of Parents and Children On Board')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjxWvTEBqc2W",
        "cellView": "form"
      },
      "source": [
        "#@title famsize\n",
        "## FAMILY SIZE\n",
        "sns.set(rc={'figure.figsize':(16, 4)})\n",
        "fig, ax = plt.subplots(1,2)\n",
        "\n",
        "sns.barplot(x = 'FamSize', y = 'Survived', data = traindf, ax=ax[0])\n",
        "ax[0].set_title('Percentage of Surivors by Number of Family Members On Board')\n",
        "\n",
        "sns.countplot(x = 'FamSize', data = traindf, ax=ax[1])\n",
        "ax[1].set_title('Total Number of Family Members On Board')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ1Z-x0-hMJi",
        "cellView": "form"
      },
      "source": [
        "#@title embarked\n",
        "## EMABARKED\n",
        "sns.set(rc={'figure.figsize':(14, 7)})\n",
        "fig, ax = plt.subplots(1,2)\n",
        "\n",
        "sns.barplot(x = 'Embarked', y = 'Survived', data = traindf, ax=ax[0])\n",
        "ax[0].set_title('Percentage of Surivors by Port of Embarkation')\n",
        "\n",
        "sns.countplot(x = 'Embarked', data = traindf, ax=ax[1])\n",
        "ax[1].set_title('Total Number of People from each Port of Embarkation')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0rdmfA8-MRy",
        "cellView": "form"
      },
      "source": [
        "#@title age\n",
        "## AGE\n",
        "sns.set(rc={'figure.figsize':(22, 7)})\n",
        "fig, ax = plt.subplots(1,2)\n",
        "\n",
        "sns.barplot(x = 'AgeBin', y = 'Survived', data = traindf, ax=ax[0])\n",
        "ax[0].set_title('Percentage of Survivors in each Age Group')\n",
        "\n",
        "sns.countplot(x = 'AgeBin', data = traindf, ax=ax[1])\n",
        "ax[1].set_title('Total Number of People in each Age Group')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp5KIZBqgMUk",
        "cellView": "form"
      },
      "source": [
        "#@title fare\n",
        "## FARE\n",
        "fig, ax = plt.subplots(1,2)\n",
        "\n",
        "sns.barplot(x = 'FareBin', y = 'Survived', data = traindf, ax=ax[0])\n",
        "ax[0].set_title('Percentage of Survivors in each Fare Group')\n",
        "\n",
        "sns.countplot(x = 'FareBin', data = traindf, ax=ax[1])\n",
        "ax[1].set_title('Total Number of People in each Fare Group')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih-rwjCQq-aS",
        "cellView": "form"
      },
      "source": [
        "#@title embarked by sex\n",
        "## EMABARKED by Sex\n",
        "\n",
        "sns.set(rc={'figure.figsize':(14, 7)})\n",
        "fig, ax = plt.subplots(1,2)\n",
        "\n",
        "sns.barplot(x = 'Embarked', y = 'Survived', data = traindf, ax=ax[0])\n",
        "ax[0].set_title('Percentage of Surivors by Port of Embarkation')\n",
        "\n",
        "sns.countplot(x = 'Embarked', hue = 'Sex', data = traindf, ax=ax[1])\n",
        "ax[1].set_title('Total Number of Females/Males from each Port of Embarkation')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ykaMeQUsrmt",
        "cellView": "form"
      },
      "source": [
        "#@title farebin by sex\n",
        "## FAREBIN By Sex\n",
        "\n",
        "sns.set(rc={'figure.figsize':(22, 7)})\n",
        "fig, ax = plt.subplots(1,2)\n",
        "\n",
        "sns.barplot(x = 'FareBin', y = 'Survived', data = traindf, ax=ax[0])\n",
        "ax[0].set_title('Percentage of Surivors by Fare Bin')\n",
        "\n",
        "sns.countplot(x = 'FareBin', hue = 'Sex', data = traindf, ax=ax[1])\n",
        "ax[1].set_title('Total Number of Females/Males in each Fare Bin')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKZZzbhlE0_N"
      },
      "source": [
        "Random Forest, Decision Tree, and KNN Models accuracy using all features are compared for the following:\n",
        "1. Without standardization\n",
        "2. With standardization of all features\n",
        "3. Standardization without 'Sex' and 'Embarked' (the non numerical features)\n",
        "4. With () standardization and PCA\n",
        "\n",
        "**current highest score is 0.81710**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8zzpxwyUvAp",
        "cellView": "form"
      },
      "source": [
        "#@title import libraries\n",
        "#import needed libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNEMuaPVj1gX",
        "cellView": "form"
      },
      "source": [
        "#@title clean data\n",
        "#clean data\n",
        "traindf_drop = traindf.dropna()\n",
        "traindf_drop['Survived'].count() #did not remove missing values bc it brought total rows of data down to 33,881 rows\n",
        "\n",
        "#replace sex and port of embarkation with numbers ()\n",
        "traindf['Sex'] = traindf['Sex'].map({'male':0, 'female':1})\n",
        "traindf['Embarked'] = traindf['Embarked'].map({'S':0, 'Q':1, 'C':2})\n",
        "\n",
        "#copied over essential features for analysis (total 6 features and 1 class label)\n",
        "df = traindf[['Survived','Pclass','Sex','Embarked','Age','Fare','FamSize']].copy()\n",
        "\n",
        "#remove missing values\n",
        "newdf = df.dropna()\n",
        "newdf['Survived'].count() #total rows of data is now 96,332\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLO1Ev6AFkT9"
      },
      "source": [
        "1. Without standardization:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKM0oqtXnJUB",
        "cellView": "form"
      },
      "source": [
        "#@title w/o standardization\n",
        "#separate features and class label\n",
        "X = newdf.drop(columns=['Survived'])\n",
        "y = newdf['Survived']\n",
        "\n",
        "#split the given train data into training and testing data to test model accuracy\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)\n",
        "\n",
        "#random forest classifier\n",
        "rf = RandomForestClassifier(max_depth=7, random_state=0)\n",
        "rf.fit(X_train,y_train)\n",
        "y_predrf = rf.predict(X_test)\n",
        "rf_acc = accuracy_score(y_test, y_predrf)\n",
        "print('Accuracy of Random Forests: ' + str(rf_acc))\n",
        "\n",
        "#decision tree classifier\n",
        "dt = DecisionTreeClassifier(max_depth=7, random_state=0)\n",
        "dt.fit(X_train,y_train)\n",
        "y_preddt = dt.predict(X_test)\n",
        "dt_acc = accuracy_score(y_test, y_preddt)\n",
        "print('Accuracy of Decision Trees: ' + str(dt_acc))\n",
        "\n",
        "#k neighbors \n",
        "#knn = KNeighborsClassifier(n_neighbors=6)\n",
        "#knn.fit(X_train,y_train)\n",
        "#y_predknn = knn.predich t(X_test)\n",
        "#knn_acc = accuracy_score(y_test, y_predknn)\n",
        "#print('Accuracy of KNN: ' + str(knn_acc))\n",
        "\n",
        "#random state 0, test size 0.3, max_depth=2, n_neighbors=4\n",
        "#Accuracy of Random Forests: 0.7594117647058823\n",
        "#Accuracy of Decision Trees: 0.7569550173010381\n",
        "#Accuracy of KNN: 0.7111764705882353\n",
        "\n",
        "#random state 0 test size 0.5, , max_depth=2, n_neighbors=4\n",
        "#Accuracy of Random Forests: 0.7582734709130923\n",
        "#Accuracy of Decision Trees: 0.7570277789311963\n",
        "#Accuracy of KNN: 0.7030062699829756\n",
        "\n",
        "#max_depth=None, n_neighbors=6\n",
        "#Accuracy of Random Forests: 0.7246712802768166\n",
        "#Accuracy of Decision Trees: 0.6832525951557094\n",
        "#Accuracy of KNN: 0.722076124567474\n",
        "\n",
        "#max_depth=4\n",
        "#Accuracy of Random Forests: 0.7706920415224914\n",
        "#Accuracy of Decision Trees: 0.76560553633218\n",
        "\n",
        "#max_depth=5\n",
        "#Accuracy of Random Forests: 0.7708996539792388\n",
        "#Accuracy of Decision Trees: 0.768235294117647\n",
        "\n",
        "#max_depth=6\n",
        "#Accuracy of Random Forests: 0.7715916955017301\n",
        "#Accuracy of Decision Trees: 0.7702076124567474\n",
        "\n",
        "#max_depth=7\n",
        "#Accuracy of Random Forests: 0.7715224913494809\n",
        "#Accuracy of Decision Trees: 0.7683737024221453"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VOnPukfFoJV"
      },
      "source": [
        "2. With standardization of all "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7SON-E-HyIR",
        "cellView": "form",
        "outputId": "962b8a5e-d19f-4506-d942-8ffde824fd70"
      },
      "source": [
        "#@title all standardization\n",
        "#separate features and class label\n",
        "X = newdf.drop(columns=['Survived'])\n",
        "y = newdf['Survived']\n",
        "\n",
        "#standardize features with StandardScalar\n",
        "colnames = X.columns\n",
        "X = StandardScaler().fit_transform(X)\n",
        "X = pd.DataFrame(X, columns=colnames)\n",
        "\n",
        "#split the given train data into training and testing data to test model accuracy\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)\n",
        "\n",
        "#random forest classifier\n",
        "rf = RandomForestClassifier(max_depth=7, random_state=0)\n",
        "rf.fit(X_train,y_train)\n",
        "y_predrf = rf.predict(X_test)\n",
        "rf_acc = accuracy_score(y_test, y_predrf)\n",
        "print('Accuracy of Random Forests with Standardization: ' + str(rf_acc))\n",
        "\n",
        "#decision tree classifier\n",
        "dt = DecisionTreeClassifier(max_depth=7, random_state=0)\n",
        "dt.fit(X_train,y_train)\n",
        "y_preddt = dt.predict(X_test)\n",
        "dt_acc = accuracy_score(y_test, y_preddt)\n",
        "print('Accuracy of Decision Trees with Standardization: ' + str(dt_acc))\n",
        "\n",
        "#k neighbors \n",
        "#knn = KNeighborsClassifier(n_neighbors=6)\n",
        "#knn.fit(X_train,y_train)\n",
        "#y_predknn = knn.predict(X_test)\n",
        "#knn_acc = accuracy_score(y_test, y_predknn)\n",
        "#print('Accuracy of KNN with Standardization: ' + str(knn_acc))\n",
        "\n",
        "#random state 0, test size 0.3,  max_depth=2, n_neighbors=4\n",
        "#Accuracy of Random Forests with Standardization: 0.7594117647058823\n",
        "#Accuracy of Decision Trees with Standardization: 0.7569550173010381\n",
        "#Accuracy of KNN with Standardization: 0.7272318339100347\n",
        "\n",
        "#random state 0 test size 0.3, , max_depth=5, n_neighbors=6\n",
        "#Accuracy of Random Forests with Standardization: 0.7708996539792388\n",
        "#Accuracy of Decision Trees with Standardization: 0.768235294117647\n",
        "#Accuracy of KNN with Standardization: 0.7399307958477509\n",
        "\n",
        "#max_depth=6\n",
        "#Accuracy of Random Forests with Standardization: 0.7715916955017301\n",
        "#Accuracy of Decision Trees with Standardization: 0.7702076124567474"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Random Forests with Standardization: 0.7715224913494809\n",
            "Accuracy of Decision Trees with Standardization: 0.7684083044982699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlwhBP22LhJX"
      },
      "source": [
        "3. Standardization of  without 'Sex' and 'Embarked' (the non numerical features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ckJc1ULloU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "3beec0f8-60f4-40a9-e8fc-6da13538a5b6"
      },
      "source": [
        "#@title selective standardization\n",
        "#standardize selected features with StandardScalar\n",
        "#Xx = newdf.drop(columns=['Survived','Sex','Embarked'])\n",
        "#colnames = Xx.columns\n",
        "#Xx = StandardScaler().fit_transform(Xx)\n",
        "#Xx = pd.DataFrame(Xx, columns=colnames)\n",
        "\n",
        "#add back 'Sex' and 'Embarked' without standardization\n",
        "#Xs = newdf.drop(columns=['Survived','Pclass','Age','Fare','FamSize'])\n",
        "#Xs = Xs.reset_index() #remove passengerid index column so there are no NaN when concatenating\n",
        "\n",
        "#X = pd.concat([Xx, Xs], axis=1)\n",
        "#y = newdf['Survived']\n",
        "\n",
        "#split the given train data into training and testing data to test model accuracy\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)\n",
        "\n",
        "#random forest classifier\n",
        "rf = RandomForestClassifier(max_depth=9, random_state=0)\n",
        "rf.fit(X_train,y_train)\n",
        "y_predrf = rf.predict(X_test)\n",
        "rf_acc = accuracy_score(y_test, y_predrf)\n",
        "print('Accuracy of Random Forests with selective Standardization: ' + str(rf_acc))\n",
        "\n",
        "#decision tree classifier\n",
        "#dt = DecisionTreeClassifier(max_depth=5, random_state=0)\n",
        "#dt.fit(X_train,y_train)\n",
        "#y_preddt = dt.predict(X_test)\n",
        "#dt_acc = accuracy_score(y_test, y_preddt)\n",
        "#print('Accuracy of Decision Trees with selective Standardization: ' + str(dt_acc))\n",
        "\n",
        "#k neighbors \n",
        "#knn = KNeighborsClassifier(n_neighbors=4)\n",
        "#knn.fit(X_train,y_train)\n",
        "#y_predknn = knn.predict(X_test)\n",
        "#knn_acc = accuracy_score(y_test, y_predknn)\n",
        "#print('Accuracy of KNN with selective Standardization: ' + str(knn_acc))\n",
        "\n",
        "#random state 0, test size 0.3\n",
        "#Accuracy of Random Forests with selective Standardization: 0.7575778546712802\n",
        "#Accuracy of Decision Trees with selective Standardization: 0.7569550173010381\n",
        "#Accuracy of KNN with selective Standardization: 0.5523875432525952"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Random Forests with selective Standardization: 0.7710034602076125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxG2CZyJFqVR"
      },
      "source": [
        "4. With standardization and PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u62n9BZHy00"
      },
      "source": [
        "#separate features and class label\n",
        "X = newdf.drop(columns=['Survived'])\n",
        "y = newdf['Survived']\n",
        "\n",
        "#standardize features with StandardScalar\n",
        "colnames = X.columns\n",
        "X = StandardScaler().fit_transform(X)\n",
        "X = pd.DataFrame(X, columns=colnames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-X5gqwUXZlU"
      },
      "source": [
        "#PCA\n",
        "#Identify the components and tranforms the data into those new dimensions\n",
        "pca = PCA(n_components=4)\n",
        "principalComponents = pca.fit_transform(X)\n",
        "\n",
        "#Can we understand how much information is retained by considering each PC? \n",
        "#print(pca.explained_variance_ratio_.cumsum())\n",
        "#[0.32448071 0.51622559 0.67445918 0.80498146 0.91138171 1.        ]\n",
        "\n",
        "#Making sure we are saving these new feature dataset into a new dataframe\n",
        "X_trans=pd.DataFrame(data = principalComponents, columns=['pca1','pca2','pca3','pca4'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTLxAQw1U5vC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16bcd117-0000-4ded-ec3a-fa3842a7eac7"
      },
      "source": [
        "#Use the above transformed df as the dataset and build a classifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_trans, y, random_state=0, test_size=0.3)\n",
        "\n",
        "#random forest classifier\n",
        "rf = RandomForestClassifier(max_depth=7, random_state=0)\n",
        "rf.fit(X_train,y_train)\n",
        "y_predrf = rf.predict(X_test)\n",
        "rf_acc = accuracy_score(y_test, y_predrf)\n",
        "print('Accuracy of Random Forests with PCA: ' + str(rf_acc))\n",
        "\n",
        "#decision tree classifier\n",
        "dt = DecisionTreeClassifier(max_depth=6, random_state=0)\n",
        "dt.fit(X_train,y_train)\n",
        "y_preddt = dt.predict(X_test)\n",
        "dt_acc = accuracy_score(y_test, y_preddt)\n",
        "print('Accuracy of Decision Trees with PCA: ' + str(dt_acc))\n",
        "\n",
        "#k neighbors \n",
        "knn = KNeighborsClassifier(n_neighbors=4)\n",
        "knn.fit(X_train,y_train)\n",
        "y_predknn = knn.predict(X_test)\n",
        "knn_acc = accuracy_score(y_test, y_predknn)\n",
        "print('Accuracy of KNN with PCA: ' + str(knn_acc))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Random Forests with PCA: 0.7673702422145329\n",
            "Accuracy of Decision Trees with PCA: 0.7662283737024221\n",
            "Accuracy of KNN with PCA: 0.7253979238754326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aifvAg44ao4m"
      },
      "source": [
        "**Comparison of different models**\n",
        "1. Accuracy of Random Forests, max depth 6: 0.7715916955017301\n",
        "2. Accuracy of Random Forests with all features Standardization, max depth 6: 0.7715916955017301\n",
        "3. Accuracy of Random Forests with selective Standardization: 0.7575778546712802\n",
        "4. Accuracy of Random Forests with PCA: 0.7572318339100346\n",
        "\n",
        "In add 4 cases, random forests classifier performed the best, with 1. and 2. having the same accuracy score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HUcG6LjcMMi"
      },
      "source": [
        "**Adding test case for model submission**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCQItXC98KvC",
        "outputId": "17d0c873-87d5-4845-d8a7-215a3d27edd7"
      },
      "source": [
        "%reset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzJLlDiqcLb_"
      },
      "source": [
        "import numpy as np\n",
        "#replace sex and port of embarkation with numbers ()\n",
        "traindf['Sex'] = traindf['Sex'].map({'male':0, 'female':1})\n",
        "traindf['Embarked'] = traindf['Embarked'].map({'S':0, 'Q':1, 'C':2})\n",
        "\n",
        "testdf['Sex'] = testdf['Sex'].map({'male':0, 'female':1})\n",
        "testdf['Embarked'] = testdf['Embarked'].map({'S':0, 'Q':1, 'C':2})\n",
        "\n",
        "#copied over essential features for analysis (total 6 features and 1 class label)\n",
        "traindf = traindf[['Survived','Pclass','Sex','Embarked','Age','Fare','FamSize']].copy()\n",
        "testdf = testdf[['Pclass','Sex','Embarked','Age','Fare','FamSize']].copy()\n",
        "\n",
        "#drop missing values\n",
        "traindf = traindf.dropna()\n",
        "\n",
        "#label\n",
        "X_train = traindf.drop(columns=['Survived'])\n",
        "y_train = traindf['Survived']\n",
        "X_test = testdf.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMbJQU_defFn"
      },
      "source": [
        "#random forest classifier\n",
        "#rf = RandomForestClassifier(max_depth=6, random_state=0)\n",
        "#rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K1fbooOmi5u"
      },
      "source": [
        "ans = pd.DataFrame(y_pred, index=testdf.index, columns=['Survived'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k7iESvRn4WC"
      },
      "source": [
        "ans.to_csv('syn_rf.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8WLdw5YgpPY6",
        "outputId": "f251a6e5-3a5f-4d86-f25d-716d1d92be4b"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"syn_rf.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2beea546-9a2a-47b1-a069-f2ce2ea41628\", \"syn_rf.csv\", 900021)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}